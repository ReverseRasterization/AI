{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72e548d",
   "metadata": {},
   "source": [
    "# Choose a Data Set\n",
    "\n",
    "You can choose to analyze any data that you would like! Remember, you need 1000 rows of non-null data in order to get 5 points for the \"Data\" criteria of my [rubric](https://docs.google.com/document/d/1s3wllcF3LLnytxwD8mZ-BCypXKnfaahnizWGNojT-B4/edit?usp=sharing). Consider looking at [Kaggle](https://www.kaggle.com/datasets) or [free APIs](https://free-apis.github.io/#/browse) for datasets of this size. Alternatively, you can scrape the web to make your own dataset! :D\n",
    "\n",
    "Once you have chosen your dataset, please read your data into a dataframe and call `.info()` below. If you don't call `info` I will give you 0 points for the first criteria described on the [rubric](https://docs.google.com/document/d/1s3wllcF3LLnytxwD8mZ-BCypXKnfaahnizWGNojT-B4/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71eb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a dataframe and call info()\n",
    "    # Example call:\n",
    "    # df = pd.DataFrame({\"A\":[1, 2, 3], \"B\":[4, 5, 6]})\n",
    "    # df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5205eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "samples = 1000\n",
    "terminationCodes = [429, 403, 401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a047341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16402125078225507"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web Crawler\n",
    "\n",
    "def getLinksAndImages(url):\n",
    "    # Get html \n",
    "    # ...requests the page, if denied then terminate the crawler\n",
    "    # ...if failed, return error\n",
    "\n",
    "    page = requests.get(url)\n",
    "\n",
    "    if page.status_code in terminationCodes:\n",
    "        return 'ERR_T'\n",
    "    elif page.status_code != 200:\n",
    "        return \"ERR\"\n",
    "    \n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Scrape for links\n",
    "    # ... isolate wikipedia article links\n",
    "    # ... check for compatibility (>3 Links)\n",
    "\n",
    "    links = [\n",
    "        link.get('href') for link in set(soup.find_all('a')) # Using the set method to avoid duplicates\n",
    "        if link.get('href') \n",
    "        and '/wiki/' in link.get('href')\n",
    "        and '#' not in link.get('href')\n",
    "        and ':' not in link.get('href')\n",
    "        and link.get('href') != '/wiki/Main_Page'\n",
    "    ]\n",
    "\n",
    "    if len(links) <= 3: return 'ERR_C'\n",
    "\n",
    "    # Scrape for images\n",
    "\n",
    "    imageCount = len(soup.find_all('img'))\n",
    "\n",
    "    return {\n",
    "        'Article': [url],\n",
    "        'Image Count': [imageCount],\n",
    "        'Links': [links]\n",
    "    }\n",
    "\n",
    "def getEmissions(url):\n",
    "    # Get emission data\n",
    "\n",
    "    emissionData = requests.get(f'https://api.websitecarbon.com/site?url={urllib.parse.quote(url, safe=\"\")}')\n",
    "\n",
    "    if emissionData.status_code in terminationCodes:\n",
    "        return 'ERR_T'\n",
    "    elif emissionData.status_code != 200:\n",
    "        return 'ERR'\n",
    "    \n",
    "    emissionData = json.loads(emissionData.text)\n",
    "\n",
    "    return emissionData['statistics']['co2']['grid']['grams']\n",
    "\n",
    "\n",
    "\n",
    "getEmissions('https://en.wikipedia.org/wiki/Competition_climbing')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e5f57",
   "metadata": {},
   "source": [
    "# My Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af0ecd",
   "metadata": {},
   "source": [
    "### Write your question here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070cec5",
   "metadata": {},
   "source": [
    "# My Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbfebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a374a3",
   "metadata": {},
   "source": [
    "# My Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cadbfec",
   "metadata": {},
   "source": [
    "### Write your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
