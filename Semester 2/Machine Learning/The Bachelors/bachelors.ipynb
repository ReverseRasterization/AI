{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b940825",
   "metadata": {},
   "source": [
    "# RFP: Betting on the Bachelor\n",
    "\n",
    "## Project Overview\n",
    "You are invited to submit a proposal that answers the following question:\n",
    "\n",
    "### Who will win season 29 of the Bachelor?\n",
    "\n",
    "*All proposals must be submitted by **1/15/25 at 11:59 PM**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a85f0",
   "metadata": {},
   "source": [
    "## Required Proposal Components\n",
    "\n",
    "### 1. Data Description\n",
    "In the code cell below, read in the data you plan on using to train and test your model. Call `info()` once you have read the data into a dataframe. Consider using some or all of the following sources:\n",
    "- [Scrape Fandom Wikis](https://bachelor-nation.fandom.com/wiki/The_Bachelor) or [the official Bachelor website]('https://bachelornation.com/shows/the-bachelor/')\n",
    "- [Ask ChatGPT to genereate it](https://chatgpt.com/)\n",
    "- [Read in csv files like this](https://www.kaggle.com/datasets/brianbgonz/the-bachelor-contestants?select=contestants.csv)\n",
    "\n",
    "*Note, a level 5 dataset contains at least 1000 rows of non-null data. A level 4 contains at least 500 rows of non-null data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c1688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a dataframe\n",
    "# Don't forget to call info()!\n",
    "\n",
    "import pandas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bachelors = { # Note: Age is whenever the person was the bachelor\n",
    "    \"Name\" : [],\n",
    "    \"Age\" : [],\n",
    "    \"Hometown\" : [],\n",
    "    \"Occupation\" : [],\n",
    "    \"Season\" : [] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e27d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtml(url):\n",
    "    try:\n",
    "        html = requests.get(url)\n",
    "        html.raise_for_status()\n",
    "        return html\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to get url data: {url}\")\n",
    "        raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a12ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['Alexander Mattheus \"Alex\" Michel', 'Andrew James \"Andy\" Baldwin', 'Stephen Bradley \"Brad\" Womack', 'Matthew Christian \"Matt\" Grant', 'Jason Scott Mesnick', 'Jake Pavelka', 'Stephen Bradley \"Brad\" Womack', 'Benjamin Flajnik', 'Sean Thomas Lowe', 'Juan Pablo Galavis Guinand', 'Christopher Douglas \"Chris\" Soules', 'Aaron Grant Buerge', 'Benjamin Edward \"Ben\" Higgins', 'Nicholas Joseph Viall', 'Arie Luyendyk Jr.', 'Colton Scott Underwood', 'Peter Weber', 'Matt James', 'Clayton Ray Echard', 'Zach Shallcross', 'Joey Graziadei', 'Grant Ellis', 'Andrew Boulton Firestone', 'Robert \"Bob\" Guiney', 'Jesse James Palmer', 'Byron Paul Velvick', 'Charles \"Charlie\" O\\'Connell', 'Travis Lane Stork', 'Prince Lorenzo Borghese'], 'Age': [], 'Hometown': ['Charlottesville, Virginia', 'Lancaster, Pennsylvania', 'Livingston, Texas', 'London, United Kingdom', 'Kirkland, Washington', 'Dallas, Texas', 'Livingston, Texas', 'Sonoma, California', 'Arlington, Texas', 'Miami, Florida', 'Lamont, Iowa', 'Butler, Missouri', 'Warsaw, Indiana', 'Milwaukee, Wisconsin', 'Den Bosch, Netherlands', 'Denver, Colorado', 'Westlake Village, California', 'New York City, New York', 'Eureka, Missouri', 'Anaheim Hills, California', 'Royersford, Pennsylvania', 'Newark, New Jersey', 'Santa Barbara, California', 'Riverview, Michigan', 'Nepean, Ontario', 'Downey, California', 'New York City, New York', 'Fort Collins, Colorado', 'Milan, Italy'], 'Occupation': ['Management consultant', 'US Navy Officer', 'Entrepreneur', 'Global financier', 'Account executive', 'Pilot', 'Entrepreneur', 'Winemaker', 'Reality TV personalityAuthor', 'Former professional soccer player', 'Farmer', 'Banker', 'Software salesman', 'Software sales executive', 'Race car driver', 'Former NFL player', 'Pilot', 'Real estate broker andentrepreneur', 'Medical sales representative', 'Tech executive', 'Tennis Pro', 'Day Trader', 'Sales manager of Firestone Family estates', 'Creator of a mortgage company', 'College football player', 'Professional bass fisherman (retired)', 'Actor', 'Doctor', 'Cosmetics entrepreneur'], 'Season': []}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the seasons\n",
    "seasonList = []\n",
    "\n",
    "html = getHtml(\"https://bachelor-nation.fandom.com/wiki/Category:The_Bachelor_seasons\")\n",
    "\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "for season in soup.find_all('li', class_=\"category-page__member\")[1:]:\n",
    "    seasonList.append(\"/wiki/\" + season.text.strip())\n",
    "\n",
    "# Iterate through each season\n",
    "# ... first, find the bachelor, then get the data on said bachelor\n",
    "# ... then, get the contestants\n",
    "\n",
    "for season in seasonList:\n",
    "\n",
    "    # Get html for the season\n",
    "\n",
    "    html = getHtml(f'https://bachelor-nation.fandom.com{season}')\n",
    "\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "    bachelor = soup.find('div', attrs={'data-source':'bachelor'}).find('a').get('href')\n",
    "\n",
    "    # Get html for the bachelor\n",
    "\n",
    "    html = getHtml(f'https://bachelor-nation.fandom.com{bachelor}')\n",
    "\n",
    "    bSoup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "    bachelors['Name'].append(bSoup.find('div', attrs={'data-source':'name'}).find('div').text)\n",
    "    bachelors['Hometown'].append(bSoup.find('div', attrs={'data-source':'hometown'}).find('div').text)\n",
    "    bachelors['Occupation'].append(bSoup.find('div', attrs={'data-source':'occupation'}).find('div').text)\n",
    "\n",
    "print(bachelors)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff05f",
   "metadata": {},
   "source": [
    "### 2. Training Your Model\n",
    "In the cell seen below, write the code you need to train a linear regression model. Make sure you display the equation of the plane that best fits your chosen data at the end of your program. \n",
    "\n",
    "*Note, level 5 work trains a model using only the standard Python library and Pandas. A level 5 model is trained with at least two features, where one of the features begins as a categorical value (e.g. occupation, hometown, etc.). A level 4 uses external libraries like scikit or numpy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a87a9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train model here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Don't forget to display the equation of the plane that best fits your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2b903",
   "metadata": {},
   "source": [
    "### 3. Testing Your Model\n",
    "In the cell seen below, write the code you need to test your linear regression model. \n",
    "\n",
    "*Note, a model is considered a level 5 if it achieves at least 60% prediction accuracy or achieves an RMSE of 2 weeks or less.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f8b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343eb3f7",
   "metadata": {},
   "source": [
    "### 4. Final Answer\n",
    "\n",
    "In the first cell seen below, state the name of your predicted winner. \n",
    "In the second cell seen below, justify your prediction using an evaluation technique like RMSE or percent accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25533722",
   "metadata": {},
   "source": [
    "#### State the name of your predicted winner here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29adde2",
   "metadata": {},
   "source": [
    "#### Justify your prediction here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
