{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = pd.read_csv('diffusion_db_unaltered.csv')\n",
    "nsfw_words = pd.read_csv('nsfw_words.csv')\n",
    "sfw_words = pd.read_csv('sfw_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell handles preliminary variables such as p(NSFW) and p(SFW) which determine the probability a prompt is nsfw or sfw using the image_nsfw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "91189\n",
      "0.0850015\n",
      "0.9149985\n"
     ]
    }
   ],
   "source": [
    "prompt_count = len(data)\n",
    "nsfw_count = len(data[data['image_nsfw'] >= .5])\n",
    "sfw_count = len(data[data['image_nsfw'] < .5])\n",
    "\n",
    "p_nsfw = nsfw_count / prompt_count\n",
    "p_sfw = sfw_count / prompt_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = [\n",
    "    \"the\", \"a\", \"an\", \"is\", \"are\", \"and\", \"to\", \"in\", \"that\", \"have\", \"has\", \n",
    "    \"with\", \"this\", \"these\", \"those\", \"it\", \"for\", \"on\", \"be\", \"was\", \"were\", \n",
    "    \"can\", \"will\", \"would\", \"should\", \"may\", \"might\", \"do\", \"does\", \"did\", \"of\", \"its\", \"their\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPrompt(prompt):\n",
    "    prompt_list = prompt.lower().split(' ')\n",
    "    prompt_list = [word for word in prompt_list if word not in commonwords]\n",
    "    prompt = ' '.join(prompt_list)\n",
    "    return re.sub(r'[^a-zA-Z0-9 ]', '', prompt)\n",
    "\n",
    "\n",
    "\n",
    "def classifyMessage(message, alpha):\n",
    "    safe = p_sfw\n",
    "    unsafe = p_nsfw\n",
    "    \n",
    "    # This sections gets the p(word|N) and p(word|S) for each word in the message.\n",
    "    word_probs_nsfw = {}\n",
    "    word_probs_sfw = {}\n",
    "\n",
    "    for word in message.split():\n",
    "        if word not in word_probs_nsfw.keys():\n",
    "            word_probs_nsfw[word] = [alpha, 1] # First index is the probability, the second index is the amount of times that the word appears in the prompt\n",
    "            word_probs_sfw[word] = [alpha, 1]\n",
    "\n",
    "            # check if word is in nsfw_words dataframe\n",
    "            if word in nsfw_words.values:\n",
    "                word_probs_nsfw[word] = [(nsfw_words[nsfw_words['word'] == word]['count'].values[0]) / len(nsfw_words), 1]\n",
    "            else:\n",
    "                word_probs_nsfw[word] = [alpha / len(nsfw_words), 1]\n",
    "\n",
    "            if word in sfw_words.values:\n",
    "                word_probs_sfw[word] = [(sfw_words[sfw_words['word'] == word]['count'].values[0])  / len(sfw_words), 1]\n",
    "            else:\n",
    "                word_probs_sfw[word] = [alpha / len(sfw_words), 1]\n",
    "        else:\n",
    "            word_probs_nsfw[word][1]+=1\n",
    "            word_probs_sfw[word][1]+=1\n",
    "\n",
    "    for word in word_probs_nsfw.keys():\n",
    "        # multiply safe and unsafe probabilities by the word probabilities but each probability is to the exponent of the amount of occurances\n",
    "        safe *= word_probs_sfw[word][0] ** word_probs_sfw[word][1]\n",
    "        unsafe *= word_probs_nsfw[word][0] ** word_probs_nsfw[word][1]\n",
    "\n",
    "    # for word, score in word_probs_nsfw.items():\n",
    "    #     print(f\"{word}: {score[0]}\")\n",
    "\n",
    "    # print(\"\\nSAFE FOR WORK WORDS:\")\n",
    "\n",
    "    # for word, score in word_probs_sfw.items():\n",
    "    #     print(f\"{word}: {score[0]}\")\n",
    "\n",
    "    if safe > unsafe:\n",
    "        return \"SFW\"\n",
    "    else:\n",
    "        return \"NSFW\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.read_csv('examples.csv')['Prompt']\n",
    "\n",
    "results = {\n",
    "    \"Prompt\": [],\n",
    "    \"Results\": []\n",
    "}\n",
    "\n",
    "for example in examples:\n",
    "    result = classifyMessage(cleanPrompt(example), 1)\n",
    "    results['Prompt'].append(example)\n",
    "    if result == \"SFW\":\n",
    "        results['Results'].append(1)\n",
    "    else:\n",
    "        results['Results'].append(0)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4878048780487805\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv('results.csv')['Results']\n",
    "examples = pd.read_csv('examples.csv')['Results']\n",
    "\n",
    "score = 0\n",
    "for i in range(len(results)):\n",
    "    if results[i] == examples[i]:\n",
    "        score += 1\n",
    "\n",
    "print(f\"Accuracy: {score / len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
