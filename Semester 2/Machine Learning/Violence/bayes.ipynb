{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('diffusion_db_unaltered.csv')\n",
    "nsfw_words = pd.read_csv('nsfw_words.csv')\n",
    "sfw_words = pd.read_csv('sfw_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell handles preliminary variables such as p(NSFW) and p(SFW) which determine the probability a prompt is nsfw or sfw using the image_nsfw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_count = len(data)\n",
    "nsfw_count = len(data[data['image_nsfw'] >= .5])\n",
    "sfw_count = len(data[data['image_nsfw'] < .5])\n",
    "\n",
    "p_nsfw = nsfw_count / prompt_count\n",
    "p_sfw = sfw_count / prompt_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSFW\n"
     ]
    }
   ],
   "source": [
    "def classifyMessage(message, alpha):\n",
    "\n",
    "    safe = p_sfw\n",
    "    unsafe = p_nsfw\n",
    "    \n",
    "    # This sections gets the p(word|N) and p(word|S) for each word in the message.\n",
    "    word_probs_nsfw = {}\n",
    "    word_probs_sfw = {}\n",
    "\n",
    "    for word in message.split():\n",
    "        if word not in word_probs_nsfw.keys():\n",
    "            word_probs_nsfw[word] = [alpha, 1] # First index is the probability, the second index is the amount of times that the word appears in the prompt\n",
    "            word_probs_sfw[word] = [alpha, 1]\n",
    "\n",
    "            # check if word is in nsfw_words dataframe\n",
    "            if word in nsfw_words.values:\n",
    "                word_probs_nsfw[word] = [(nsfw_words[nsfw_words['word'] == word]['count'].values[0]) / len(nsfw_words), 1]\n",
    "            else:\n",
    "                word_probs_nsfw[word] = [alpha / len(nsfw_words), 1]\n",
    "\n",
    "            if word in sfw_words.values:\n",
    "                word_probs_sfw[word] = [(sfw_words[sfw_words['word'] == word]['count'].values[0]) / len(sfw_words), 1]\n",
    "            else:\n",
    "                word_probs_sfw[word] = [alpha / len(sfw_words), 1]\n",
    "        else:\n",
    "            word_probs_nsfw[word][1]+=1\n",
    "            word_probs_sfw[word][1]+=1\n",
    "\n",
    "    for word in word_probs_nsfw.keys():\n",
    "        # multiply safe and unsafe probabilities by the word probabilities but each probability is to the exponent of the amount of occurances\n",
    "        safe *= word_probs_sfw[word][0] ** word_probs_sfw[word][1]\n",
    "        unsafe *= word_probs_nsfw[word][0] ** word_probs_nsfw[word][1]\n",
    "\n",
    "    if safe > unsafe:\n",
    "        return \"SFW\"\n",
    "    else:\n",
    "        return \"NSFW\"\n",
    "\n",
    "# Example usage\n",
    "print(classifyMessage(\"Donald trump licking elon musks toes\", 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
